"""SQLAlchemy models for Reddit Analyzer."""

from sqlalchemy import (
    Column, Integer, String, Text, TIMESTAMP, Date,
    Enum, DECIMAL, JSON, BigInteger, ForeignKey, UniqueConstraint
)
from sqlalchemy.sql import func
from sqlalchemy.orm import relationship
from .connection import Base


class RedditPost(Base):
    """
    Metadata for posts from multiple sources (Reddit, HackerNews, etc).
    Table renamed to 'posts' for multi-source support.
    """
    __tablename__ = 'posts'

    id = Column(String(50), primary_key=True, comment='Prefixed post ID (reddit_abc123, hn_8863)')
    source = Column(
        Enum('reddit', 'hackernews', name='source_enum'),
        nullable=False,
        index=True,
        comment='Content source'
    )
    project = Column(
        String(50),
        nullable=False,
        default='default',
        index=True,
        comment='Project identifier (e.g., "claudeia", "wineworld")'
    )
    subreddit = Column(String(100), nullable=True, index=True, comment='Reddit: subreddit name, HN: null')
    title = Column(Text, nullable=False)
    author = Column(String(100))
    score = Column(Integer)
    num_comments = Column(Integer)
    created_utc = Column(BigInteger, index=True, comment='Unix timestamp')
    url = Column(Text)
    selftext = Column(Text, comment='Truncated to 5000 chars/MAX_LINES_ARTICLE')
    fetched_at = Column(TIMESTAMP, server_default=func.now())

    # Relationship
    classification = relationship(
        "Classification",
        back_populates="post",
        uselist=False,  # One-to-one
        cascade="all, delete-orphan"
    )

    def to_dict(self):
        """Convert model to dict."""
        return {
            'id': self.id,
            'subreddit': self.subreddit,
            'title': self.title,
            'author': self.author,
            'score': self.score,
            'num_comments': self.num_comments,
            'created_utc': self.created_utc,
            'url': self.url,
            'selftext': self.selftext
        }


class Classification(Base):
    """
    Classifications generated by Claude.
    One classification per (post_id, project) - UNIQUE KEY (post_id, project).
    """
    __tablename__ = 'classifications'

    id = Column(Integer, primary_key=True, autoincrement=True)
    post_id = Column(
        String(50),
        ForeignKey('posts.id', ondelete='CASCADE'),
        nullable=False
    )
    source = Column(
        Enum('reddit', 'hackernews', name='source_enum'),
        nullable=False,
        index=True,
        comment='Content source matching the post'
    )
    project = Column(
        String(50),
        nullable=False,
        default='default',
        index=True,
        comment='Project identifier (matches post.project)'
    )
    category = Column(
        Enum(
            'technical', 'troubleshooting', 'research_verified',
            'mystical', 'unverified_claim', 'engagement_bait',
            'community', 'meme', 'outlier',
            'unrelated',  # Posts outside topic scope
            name='category_enum'
        ),
        nullable=False,
        index=True
    )
    confidence = Column(DECIMAL(3, 2), comment='0.00-1.00')
    red_flags = Column(JSON, comment='Array of red flags')
    reasoning = Column(Text)
    model_version = Column(String(50), default='claude-haiku-4-5-20251001')
    classified_at = Column(TIMESTAMP, server_default=func.now(), index=True)
    sent_in_digest_at = Column(
        TIMESTAMP,
        nullable=True,
        comment='When this post was included in a daily digest email'
    )
    topic_tags = Column(
        JSON,
        nullable=True,
        comment='Array of topic tags: prompts, tools, models, research, coding, buildable, hardware, troubleshooting, news, meta-tooling'
    )
    format_tag = Column(
        String(50),
        nullable=True,
        comment='Format tag: tutorial, showcase, discussion, question, resource, code-snippet'
    )
    digest_date = Column(
        Date,
        nullable=True,
        index=True,
        comment='Date of the digest this post was included in'
    )
    # Multi-tier tagging system (9 tiers + scoring + clusters)
    tier_tags = Column(
        JSON,
        nullable=True,
        comment='9-tier classification structure: {tier1: [...], tier2: [...], ..., tier9: [...]}'
    )
    tier_clusters = Column(
        JSON,
        nullable=True,
        comment='Array of detected cluster descriptions from tier analysis'
    )
    tier_scoring = Column(
        Integer,
        nullable=True,
        comment='Scoring 30-95 based on tier pattern analysis'
    )

    # UNIQUE constraint on (post_id, project)
    __table_args__ = (
        UniqueConstraint('post_id', 'project', name='unique_post_project'),
    )

    # Relationship
    post = relationship("RedditPost", back_populates="classification")

    def to_dict(self):
        """Convert model to dict."""
        return {
            'post_id': self.post_id,
            'category': self.category,
            'confidence': float(self.confidence) if self.confidence else None,
            'red_flags': self.red_flags or [],
            'reasoning': self.reasoning,
            'model_version': self.model_version,
            'topic_tags': self.topic_tags or [],
            'format_tag': self.format_tag,
            'tier_tags': self.tier_tags,
            'tier_clusters': self.tier_clusters or [],
            'tier_scoring': self.tier_scoring,
            'digest_date': str(self.digest_date) if self.digest_date else None
        }


class ScanHistory(Base):
    """
    Scan history for tracking and analytics (multi-source support).
    """
    __tablename__ = 'scan_history'

    id = Column(Integer, primary_key=True, autoincrement=True)
    subreddit = Column(String(100), nullable=True, index=True, comment='Subreddit name (reddit) or "HackerNews" (HN)')
    source = Column(
        Enum('reddit', 'hackernews', name='source_enum'),
        nullable=True,
        index=True,
        comment='Content source for this scan'
    )
    project = Column(
        String(50),
        nullable=False,
        default='default',
        index=True,
        comment='Project identifier for this scan'
    )
    scan_date = Column(TIMESTAMP, server_default=func.now(), index=True)
    posts_fetched = Column(Integer, comment='Total posts from Reddit')
    posts_classified = Column(Integer, comment='New posts classified')
    posts_cached = Column(Integer, comment='Posts from cache')
    signal_ratio = Column(DECIMAL(5, 2), comment='Signal percentage')

    def to_dict(self):
        """Convert model to dict."""
        return {
            'subreddit': self.subreddit,
            'scan_date': self.scan_date,
            'posts_fetched': self.posts_fetched,
            'posts_classified': self.posts_classified,
            'posts_cached': self.posts_cached,
            'signal_ratio': float(self.signal_ratio) if self.signal_ratio else None
        }


class Bookmark(Base):
    """
    User bookmarks for interesting stories from digests.
    Denormalized to avoid JOINs - data captured at bookmark time.
    """
    __tablename__ = 'bookmarks'

    id = Column(Integer, primary_key=True, autoincrement=True)

    # Story identification
    story_id = Column(
        String(50),
        unique=True,
        nullable=False,
        comment='ID like "2025-01-17-003"'
    )
    digest_date = Column(Date, nullable=False, index=True, comment='Date of the digest')

    # Bookmark metadata
    bookmarked_at = Column(TIMESTAMP, server_default=func.now(), index=True)
    notes = Column(Text, nullable=True, comment='User notes')
    status = Column(
        Enum('to_read', 'to_implement', 'done', name='bookmark_status_enum'),
        nullable=False,
        default='to_read',
        index=True
    )

    # Denormalized story data (from JSON at bookmark time)
    story_title = Column(Text, nullable=False)
    story_url = Column(Text, nullable=True)
    story_source = Column(String(50), nullable=True, comment='r/ClaudeAI or HackerNews')
    story_category = Column(String(50), nullable=True, comment='technical, research, etc.')
    story_topic_tags = Column(JSON, nullable=True, comment='Array of topic tags')
    story_format_tag = Column(String(50), nullable=True, comment='tutorial, code-snippet, etc.')
    # Tier tags (denormalized from source story)
    story_tier_tags = Column(JSON, nullable=True, comment='9-tier tags from source story')
    story_tier_clusters = Column(JSON, nullable=True, comment='Cluster descriptions from source story')
    story_tier_scoring = Column(Integer, nullable=True, comment='Scoring 30-95 from source story')

    # Link to original post for traceability
    post_id = Column(
        String(50),
        nullable=True,  # Nullable for backwards compatibility with existing bookmarks
        index=True,
        comment='Original post ID (reddit_abc123 or hn_12345678)'
    )

    def to_dict(self):
        """Convert model to dict."""
        return {
            'story_id': self.story_id,
            'post_id': self.post_id,
            'digest_date': str(self.digest_date) if self.digest_date else None,
            'bookmarked_at': str(self.bookmarked_at) if self.bookmarked_at else None,
            'notes': self.notes,
            'status': self.status,
            'story_title': self.story_title,
            'story_url': self.story_url,
            'story_source': self.story_source,
            'story_category': self.story_category,
            'story_topic_tags': self.story_topic_tags or [],
            'story_format_tag': self.story_format_tag,
            'story_tier_tags': self.story_tier_tags,
            'story_tier_clusters': self.story_tier_clusters or [],
            'story_tier_scoring': self.story_tier_scoring
        }
